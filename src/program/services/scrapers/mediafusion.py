""" Mediafusion scraper module """

from typing import Dict

from loguru import logger
from requests import ConnectTimeout, ReadTimeout
from requests.exceptions import RequestException

from program.media.item import MediaItem
from program.services.scrapers.shared import (
    ScraperRequestHandler,
    _get_stremio_identifier,
)
from program.settings.manager import settings_manager
from program.settings.models import AppModel
from program.utils.request import (
    HttpMethod,
    RateLimitExceeded,
    ResponseType,
    create_service_session,
    get_rate_limit_params,
)


class Mediafusion:
    """Scraper for `Mediafusion`"""

    def __init__(self):
        self.key = "mediafusion"
        self.api_key = None
        self.downloader = None
        self.app_settings: AppModel = settings_manager.settings
        self.settings = self.app_settings.scraping.mediafusion
        self.timeout = self.settings.timeout
        self.encrypted_string = None
        # https://github.com/elfhosted/infra/blob/ci/mediafusion/middleware-ratelimit-stream.yaml
        rate_limit_params = (
            get_rate_limit_params(max_calls=1, period=10)
            if self.settings.ratelimit
            else None
        )
        session = create_service_session(rate_limit_params=rate_limit_params)
        self.request_handler = ScraperRequestHandler(session)
        self.initialized = self.validate()
        if not self.initialized:
            return
        logger.success("Mediafusion initialized!")

    def validate(self) -> bool:
        """Validate the Mediafusion settings."""
        if not self.settings.enabled:
            return False
        if not self.settings.url:
            logger.error("Mediafusion URL is not configured and will not be used.")
            return False
        if not isinstance(self.timeout, int) or self.timeout <= 0:
            logger.error("Mediafusion timeout is not set or invalid.")
            return False
        if not isinstance(self.settings.ratelimit, bool):
            logger.error("Mediafusion ratelimit must be a valid boolean.")
            return False

        payload = {
            # "selected_resolutions": [
            #     "4k", "2160p", "1440p",
            #     "1080p", "720p", "480p", None
            # ],
            "max_streams_per_resolution": 100,
            "live_search_streams": True,
            "show_full_torrent_name": True,
            "torrent_sorting_priority": [],  # Disable sort order. This doesnt matter as we sort later.
            "nudity_filter": ["Disable"],
            "certification_filter": ["Disable"],
        }

        url = f"{self.settings.url}/encrypt-user-data"
        headers = {"Content-Type": "application/json"}

        try:
            response = self.request_handler.execute(
                HttpMethod.POST,
                url,
                overriden_response_type=ResponseType.DICT,
                json=payload,
                headers=headers,
            )
            if not response.data or response.data["status"] != "success":
                logger.error(f"Failed to encrypt user data: {response.data['message']}")
                return False
            self.encrypted_string = response.data["encrypted_str"]
        except Exception as e:
            logger.error(f"Failed to encrypt user data: {e}")
            return False

        try:
            url = f"{self.settings.url}/manifest.json"
            response = self.request_handler.execute(
                HttpMethod.GET, url, timeout=self.timeout
            )
            return response.is_ok
        except Exception as e:
            logger.error(f"Mediafusion failed to initialize: {e}")
            return False

    def run(self, item: MediaItem) -> Dict[str, str]:
        """Scrape the mediafusion site for the given media items
        and update the object with scraped streams"""
        if not item:
            return {}

        try:
            return self.scrape(item)
        except RateLimitExceeded:
            logger.debug(f"Mediafusion ratelimit exceeded for item: {item.log_string}")
        except ConnectTimeout:
            logger.warning(f"Mediafusion connection timeout for item: {item.log_string}")
        except ReadTimeout:
            logger.warning(f"Mediafusion read timeout for item: {item.log_string}")
        except RequestException as e:
            logger.error(f"Mediafusion request exception: {e}")
        except Exception as e:
            logger.exception(f"Mediafusion exception thrown: {e}")
        return {}

    def scrape(self, item: MediaItem) -> tuple[Dict[str, str], int]:
        """Wrapper for `Mediafusion` scrape method"""
        identifier, scrape_type, imdb_id = _get_stremio_identifier(item)

        url = f"{self.settings.url}/{self.encrypted_string}/stream/{scrape_type}/{imdb_id}"
        if identifier:
            url += identifier

        response = self.request_handler.execute(HttpMethod.GET, f"{url}.json", timeout=self.timeout)
        if not response.is_ok or len(response.data.streams) == 0:
            logger.log("NOT_FOUND", f"No streams found for {item.log_string}")
            return {}

        torrents: Dict[str, str] = {}
        for stream in response.data.streams:
            if hasattr(stream, "title") and "rate-limit exceeded" in stream.title:
                raise RateLimitExceeded(f"Mediafusion rate-limit exceeded for item: {item.log_string}")

            if not all(hasattr(stream, "infoHash") for stream in response.data.streams):
                logger.debug("Streams were found but were filtered due to your MediaFusion settings.")
                filtered_message = stream.description.replace("🚫 Streams Found\n⚙️ Filtered by your configuration preferences\n", "")
                filtered_message = filtered_message.replace("\n", ". ").replace(" ⚙️", "").replace("🚫", "")
                logger.debug(filtered_message)
                return torrents

            description_split = stream.description.replace("📂 ", "")
            raw_title = description_split.split("\n")[0]
            if scrape_type == "series":
                if item.type == "episode":
                    raw_title = raw_title.split(" ┈➤ ")[-1].strip()
                else:
                    raw_title = raw_title.split(" ┈➤ ")[0].strip()
            info_hash = stream.infoHash
            if info_hash and info_hash not in torrents:
                torrents[info_hash] = raw_title

        if torrents:
            logger.log("SCRAPER", f"Found {len(torrents)} streams for {item.log_string}")
        else:
            logger.log("NOT_FOUND", f"No streams found for {item.log_string}")

        return torrents
